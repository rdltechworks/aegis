from local_llm_wrapper import LocalLlmWrapper

ollama_client = LocalLlmWrapper(model="llama2")